
<!DOCTYPE html>
<html lang="en" dir=>

<head>
  <meta name="generator" content="Hugo 0.80.0" />
  
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Kafka CDC #  Prepare Kafka Bundled Jar #  flink-sql-connector-kafka-*.jar Supported Formats #  Flink provides several Kafka CDC formats: Canal Json, Debezium Json, Debezium Avro, Ogg Json, Maxwell Json and Normal Json. If a message in a Kafka topic is a change event captured from another database using the Change Data Capture (CDC) tool, then you can use the Paimon Kafka CDC. Write the INSERT, UPDATE, DELETE messages parsed into the paimon table.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="Kafka CDC" />
<meta property="og:description" content="Kafka CDC #  Prepare Kafka Bundled Jar #  flink-sql-connector-kafka-*.jar Supported Formats #  Flink provides several Kafka CDC formats: Canal Json, Debezium Json, Debezium Avro, Ogg Json, Maxwell Json and Normal Json. If a message in a Kafka topic is a change event captured from another database using the Change Data Capture (CDC) tool, then you can use the Paimon Kafka CDC. Write the INSERT, UPDATE, DELETE messages parsed into the paimon table." />
<meta property="og:type" content="article" />
<meta property="og:url" content="//paimon.apache.org/docs/master/cdc-ingestion/kafka-cdc/" />

<title>Kafka CDC | Apache Paimon</title>
<link rel="manifest" href="/docs/master/manifest.json">
<link rel="icon" href="/docs/master/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/docs/master/book.min.3bc4108a5b57c9a7e6fcae92ff69940435f8c46c4e1e4a311aedc9b2d8e06792.css" integrity="sha256-O8QQiltXyafm/K6S/2mUBDX4xGxOHkoxGu3JstjgZ5I=">
<script defer src="/docs/master/en.search.min.7889fcfaf94f3471b5ad58c638c1bcc89119f9e148ce196c101f800700d43327.js" integrity="sha256-eIn8&#43;vlPNHG1rVjGOMG8yJEZ&#43;eFIzhlsEB&#43;ABwDUMyc="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
  

<link rel="stylesheet" type="text/css" href="//paimon.apache.org/docs/master/font-awesome/css/font-awesome.min.css">
<script src="//paimon.apache.org/docs/master/js/anchor.min.js"></script>
<script src="//paimon.apache.org/docs/master/js/flink.js"></script>



  
  <script>
    var _paq = window._paq = window._paq || [];
     
     
    _paq.push(['disableCookies']);
     
    _paq.push(["setDomains", ["*.flink.apache.org","*.nightlies.apache.org/flink"]]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
      var u="//matomo.privacy.apache.org/";
      _paq.push(['setTrackerUrl', u+'matomo.php']);
      _paq.push(['setSiteId', '1']);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
    })();
  </script>
  
</head>

<body dir=>
  
    <input type="checkbox" class="hidden toggle" id="menu-control" />
    <input type="checkbox" class="hidden toggle" id="toc-control" />
  
  <main class="container flex">
    
      <aside class="book-menu">
        
  

<nav>


<a id="logo" href="//paimon.apache.org/docs/master">
    <img width="100%" src="//paimon.apache.org/docs/master/paimon_black.svg">
</a>
<p style="text-align:right">1.4-SNAPSHOT</p>

<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>










  





  
  <ul>
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-dc8a1c63e6da60163016ce21cae1faa0" class="toggle"  />
    <label for="section-dc8a1c63e6da60163016ce21cae1faa0" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-book title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Concepts</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/basic-concepts/" class="">Basic Concepts</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/concurrency-control/" class="">Concurrency Control</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/catalog/" class="">Catalog</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-e03f934865df9dd3baca303554bcaa71" class="toggle"  />
    <label for="section-e03f934865df9dd3baca303554bcaa71" class="flex justify-between">RESTCatalog<span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/bear/" class="">Bear Token</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/dlf/" class="">DLF Token</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/tables/" class="">Tables</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/pvfs/" class="">PVFS</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/rest/rest-api/" class="">REST API</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/system-tables/" class="">System Tables</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/data-types/" class="">Data Types</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/functions/" class="">Functions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/views/" class="">Views</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-d3e7256ce393050c572ea7bd8cc4f240" class="toggle"  />
    <label for="section-d3e7256ce393050c572ea7bd8cc4f240" class="flex justify-between">Specification<span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/schema/" class="">Schema</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/snapshot/" class="">Snapshot</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/manifest/" class="">Manifest</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/datafile/" class="">DataFile</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/fileformat/" class="">FileFormat</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/tableindex/" class="">Table Index</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/fileindex/" class="">File Index</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/concepts/spec/blob/" class="">Blob</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-3f6a6d4f1692040009c66ffaa328c8d0" class="toggle"  />
    <label for="section-3f6a6d4f1692040009c66ffaa328c8d0" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-database title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Table with PK</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/data-distribution/" class="">Data Distribution</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/table-mode/" class="">Table Mode</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-038bb7d17b5b7cb93fb60acbcf218f11" class="toggle"  />
    <label for="section-038bb7d17b5b7cb93fb60acbcf218f11" class="flex justify-between">Merge Engine<span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/merge-engine/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/merge-engine/partial-update/" class="">Partial Update</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/merge-engine/aggregation/" class="">Aggregation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/merge-engine/first-row/" class="">First Row</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/changelog-producer/" class="">Changelog Producer</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/sequence-rowkind/" class="">Sequence & Rowkind</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/compaction/" class="">Compaction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/query-performance/" class="">Query Performance</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/primary-key-table/chain-table/" class="">Chain Table</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-f74847e1c917ba2b99e7b718bb318b30" class="toggle"  />
    <label for="section-f74847e1c917ba2b99e7b718bb318b30" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-database title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Table w/o PK</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/streaming/" class="">Streaming</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/query-performance/" class="">Query Performance</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/incremental-clustering/" class="">Incremental Clustering</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/update/" class="">Update</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/bucketed/" class="">Bucketed</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/row-tracking/" class="">Row Tracking</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/append-table/data-evolution/" class="">Data Evolution</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-998a37410d502937fe8444ed73a9ecf8" class="toggle"  />
    <label for="section-998a37410d502937fe8444ed73a9ecf8" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-gear title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Engine Flink</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/quick-start/" class="">Quick Start</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/sql-ddl/" class="">SQL DDL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/sql-write/" class="">SQL Write</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/sql-query/" class="">SQL Query</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/consumer-id/" class="">Consumer ID</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/sql-lookup/" class="">SQL Lookup</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/sql-alter/" class="">SQL Alter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/default-value/" class="">Default Value</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/procedures/" class="">Procedures</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/action-jars/" class="">Action Jars</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/flink/savepoint/" class="">Savepoint</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-74c63bf75b4f6bd14a3ea6a1217f03ad" class="toggle"  />
    <label for="section-74c63bf75b4f6bd14a3ea6a1217f03ad" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-gear title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Engine Spark</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/quick-start/" class="">Quick Start</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-ddl/" class="">SQL DDL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-functions/" class="">SQL Functions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-write/" class="">SQL Write</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-query/" class="">SQL Query</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-alter/" class="">SQL Alter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/auxiliary/" class="">Auxiliary</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/default-value/" class="">Default Value</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/dataframe/" class="">DataFrame</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/sql-upsert/" class="">SQL Upsert</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/structured-streaming/" class="">Structured Streaming</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/spark/procedures/" class="">Procedures</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-16bf9de4e97c50dda6ce1ac6e934602c" class="toggle"  />
    <label for="section-16bf9de4e97c50dda6ce1ac6e934602c" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-gear title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Ecosystem</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/starrocks/" class="">StarRocks</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/doris/" class="">Doris</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/hive/" class="">Hive</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/trino/" class="">Trino</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/ecosystem/amoro/" class="">Amoro</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-582e435c19ca5fafbf9764337d648e63" class="toggle" checked />
    <label for="section-582e435c19ca5fafbf9764337d648e63" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-gear title maindish" aria-hidden="true"></i>&nbsp;&nbsp;CDC Ingestion</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/mysql-cdc/" class="">Mysql CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/postgres-cdc/" class="">Postgres CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/kafka-cdc/" class=" active">Kafka CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/mongo-cdc/" class="">Mongo CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/pulsar-cdc/" class="">Pulsar CDC</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/cdc-ingestion/flink-cdc/" class="">Flink CDC</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-697a4b6a0388d6cfa4f418aba3b4edfe" class="toggle"  />
    <label for="section-697a4b6a0388d6cfa4f418aba3b4edfe" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-wrench title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Maintenance</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/filesystems/" class="">Filesystems</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/write-performance/" class="">Write Performance</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/dedicated-compaction/" class="">Dedicated Compaction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/manage-snapshots/" class="">Manage Snapshots</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/rescale-bucket/" class="">Rescale Bucket</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/manage-tags/" class="">Manage Tags</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/metrics/" class="">Metrics</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/manage-privileges/" class="">Manage Privileges</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/manage-branches/" class="">Manage Branches</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/manage-partitions/" class="">Manage Partitions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/maintenance/configurations/" class="">Configurations</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-049030059e0dc01edf74ba3d4d259dae" class="toggle"  />
    <label for="section-049030059e0dc01edf74ba3d4d259dae" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-briefcase title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Program API</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/rest-api/" class="">REST API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/flink-api/" class="">Flink API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/java-api/" class="">Java API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/catalog-api/" class="">Catalog API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/python-api/" class="">Python API</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/program-api/cpp-api/" class="">Cpp API</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-07c567e5a9f3ce62aea4ff0a1e2dc065" class="toggle"  />
    <label for="section-07c567e5a9f3ce62aea4ff0a1e2dc065" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-briefcase title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Migration</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/migration/migration-from-hive/" class="">Migration From Hive</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/migration/migration-from-iceberg/" class="">Migration From Iceberg</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/migration/upsert-to-partitioned/" class="">Upsert To Partitioned</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/migration/clone-to-paimon/" class="">Clone To Paimon</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-dc2f2ba83b7db3b9bfa35da4c73572d2" class="toggle"  />
    <label for="section-dc2f2ba83b7db3b9bfa35da4c73572d2" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-briefcase title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Iceberg Metadata</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/overview/" class="">Overview</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/append-table/" class="">Append Table</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/primary-key-table/" class="">Primary Key Table</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/iceberg-tags/" class="">Iceberg Tags</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/hive-catalog/" class="">Hive Catalogs</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/rest-catalog/" class="">Rest Catalog</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/ecosystem/" class="">Ecosystem</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/iceberg/configurations/" class="">Configurations</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  	<br/>
  
  
    <input type="checkbox" id="section-8c828bcf882f666cdd6821a70cc768ee" class="toggle"  />
    <label for="section-8c828bcf882f666cdd6821a70cc768ee" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-sitemap title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Project</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/project/download/" class="">Download</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/project/contributing/" class="">Contributing</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/project/committer/" class="">Committer</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
  
    <input type="checkbox" id="section-392fc6f653ae23ff676811656a71ebbf" class="toggle"  />
    <label for="section-392fc6f653ae23ff676811656a71ebbf" class="flex justify-between"><div style="font-weight:450;margin-bottom:0.5em"><i class="fa fa-sitemap title maindish" aria-hidden="true"></i>&nbsp;&nbsp;Learn Paimon</div><span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
  
    <a href="//paimon.apache.org/docs/master/learn-paimon/understand-files/" class="">Understand Files</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>
















<br/>
<hr class="menu-break">

<a href="//paimon.apache.org" style="color:black;margin-bottom:0.5em"><i class="link fa fa-external-link title" aria-hidden="true"></i> Project Homepage</a>
<br/>

<a href="//paimon.apache.org/docs/master/api/java/" style="color:black;margin-bottom:0.5em"><i class="link fa fa-external-link title" aria-hidden="true"></i> JavaDocs</a>
<br/>

<hr class="menu-break">
<li style="list-style-type: none">
  <br>
  <input type="checkbox" id="section-version-picker" class="toggle">
  <label for="section-version-picker" class="flex justify-between">
     <div style="font-weight:450;margin-bottom:0.5em">Pick Docs Version</div>
     <span>▾</span>
  </label>
  <ul>
    <a href="//paimon.apache.org/docs/master">
      1.4-SNAPSHOT (✓)
    </a>
    <hr class="menu-break">
    
      <li>
        <a href="https://paimon.apache.org/docs/master">
          master
        </a>
      </li>
    
      <li>
        <a href="https://paimon.apache.org/docs/1.3">
          stable
        </a>
      </li>
    
      <li>
        <a href="https://paimon.apache.org/docs/1.3">
          1.3
        </a>
      </li>
    
      <li>
        <a href="https://paimon.apache.org/docs/1.2">
          1.2
        </a>
      </li>
    
      <li>
        <a href="https://paimon.apache.org/docs/1.1">
          1.1
        </a>
      </li>
    
    <hr class="menu-break">
    <li>
      <a href="//paimon.apache.org/docs/master/versions">
          All Versions
      </a>
    </li>
  </ul>
</li>









</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
      </aside>
    

    <div class="book-page">
      
        <header class="book-header">
          
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/docs/master/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Kafka CDC</strong>

  <label for="toc-control">
    
    <img src="/docs/master/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  

<nav id="TableOfContents"><h3>On This Page <button class="toc" onclick="collapseToc()"><i class="fa fa-compress" aria-hidden="true"></i></button></h3>
  <ul>
    <li><a href="#prepare-kafka-bundled-jar">Prepare Kafka Bundled Jar</a></li>
    <li><a href="#supported-formats">Supported Formats</a></li>
    <li><a href="#synchronizing-tables">Synchronizing Tables</a></li>
    <li><a href="#synchronizing-databases">Synchronizing Databases</a></li>
    <li><a href="#additional-kafka_config">Additional kafka_config</a></li>
    <li><a href="#debezium-bson">Debezium-bson</a></li>
  </ul>
</nav>


  </aside>
  
 
        </header>
      

      




<article class="markdown">
    <blockquote style="border-color:#f66">
        This documentation is for an unreleased version of Apache Paimon. We recommend you use the latest <a href="https://paimon.apache.org/docs/1.3">stable version</a>.
    </blockquote>
</article>



      
  <article class="markdown"><!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<h1 id="kafka-cdc">
  Kafka CDC
  <a class="anchor" href="#kafka-cdc">#</a>
</h1>
<h2 id="prepare-kafka-bundled-jar">
  Prepare Kafka Bundled Jar
  <a class="anchor" href="#prepare-kafka-bundled-jar">#</a>
</h2>
<pre><code>flink-sql-connector-kafka-*.jar
</code></pre><h2 id="supported-formats">
  Supported Formats
  <a class="anchor" href="#supported-formats">#</a>
</h2>
<p>Flink provides several Kafka CDC formats: Canal Json, Debezium Json, Debezium Avro, Ogg Json, Maxwell Json and Normal Json.
If a message in a Kafka topic is a change event captured from another database using the Change Data Capture (CDC) tool, then you can use the Paimon Kafka CDC. Write the INSERT, UPDATE, DELETE messages parsed into the paimon table.</p>
<table class="table table-bordered">
    <thead>
      <tr>
        <th class="text-left">Formats</th>
        <th class="text-left">Supported</th>
      </tr>
    </thead>
    <tbody>
        <tr>
         <td><a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/canal/">Canal CDC</a></td>
          <td>True</td>
        </tr>
        <tr>
         <td><a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/debezium/">Debezium CDC</a></td>
         <td>True</td>
        </tr>
        <tr>
         <td><a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/maxwell/">Maxwell CDC</a></td>
        <td>True</td>
        </tr>
        <tr>
         <td><a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/ogg/">OGG CDC</a></td>
        <td>True</td>
        </tr>
        <tr>
         <td><a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/json/">JSON</a></td>
        <td>True</td>
        </tr>
        <tr>
         <td><a href="https://docs.aws.amazon.com/dms/latest/userguide/Welcome.html">aws-dms-json</a></td>
        <td>True</td>
        </tr>
        <tr>
         <td>debezium-bson</td>
        <td>True</td>
        </tr>
    </tbody>
</table>
<blockquote class="book-hint info">
  <p>The JSON sources possibly missing some information. For example, Ogg and Maxwell format standards don&rsquo;t contain field
types; When you write JSON sources into Flink Kafka sink, it will only reserve data and row type and drop other information.
The synchronization job will try best to handle the problem as follows:</p>
<ol>
<li>Usually, debezium-json contains &lsquo;schema&rsquo; field, from which Paimon will retrieve data types. Make sure your debezium
json has this field, or Paimon will use &lsquo;STRING&rsquo; type.</li>
<li>If missing field types, Paimon will use &lsquo;STRING&rsquo; type as default.</li>
<li>If missing database name or table name, you cannot do database synchronization, but you can still do table synchronization.</li>
<li>If missing primary keys, the job might create non primary key table. You can set primary keys when submit job in table
synchronization.</li>
</ol>

</blockquote>

<h2 id="synchronizing-tables">
  Synchronizing Tables
  <a class="anchor" href="#synchronizing-tables">#</a>
</h2>
<p>By using <a href="/docs/master/api/java/org/apache/paimon/flink/action/cdc/kafka/KafkaSyncTableAction">KafkaSyncTableAction</a> in a Flink DataStream job or directly through <code>flink run</code>, users can synchronize one or multiple tables from Kafka&rsquo;s one topic into one Paimon table.</p>
<p>To use this feature through <code>flink run</code>, run the following shell command.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_table <span class="se">\
</span><span class="se"></span>    --warehouse &lt;warehouse-path&gt; <span class="se">\
</span><span class="se"></span>    --database &lt;database-name&gt; <span class="se">\
</span><span class="se"></span>    --table &lt;table-name&gt; <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--partition_keys &lt;partition_keys&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--primary_keys &lt;primary-keys&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--type_mapping to-string<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--computed_column &lt;<span class="s1">&#39;column-name=expr-name(args[, ...])&#39;</span>&gt; <span class="o">[</span>--computed_column ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--kafka_conf &lt;kafka-source-conf&gt; <span class="o">[</span>--kafka_conf &lt;kafka-source-conf&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--catalog_conf &lt;paimon-catalog-conf&gt; <span class="o">[</span>--catalog_conf &lt;paimon-catalog-conf&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_conf &lt;paimon-table-sink-conf&gt; <span class="o">[</span>--table_conf &lt;paimon-table-sink-conf&gt; ...<span class="o">]]</span>
</code></pre></div>

<table class="configuration table table-bordered">
    <thead>
    <tr>
        <th class="text-left" style="width: 15%">Configuration</th>
        <th class="text-left" style="width: 85%">Description</th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <td><h5>--warehouse</h5></td>
        <td>The path to Paimon warehouse.</td>
    </tr>
    <tr>
        <td><h5>--database</h5></td>
        <td>The database name in Paimon catalog.</td>
    </tr>
    <tr>
        <td><h5>--table</h5></td>
        <td>The Paimon table name.</td>
    </tr>
    <tr>
        <td><h5>--partition_keys</h5></td>
        <td>The partition keys for Paimon table. If there are multiple partition keys, connect them with comma, for example "dt,hh,mm".</td>
    </tr>
    <tr>
        <td><h5>--primary_keys</h5></td>
        <td>The primary keys for Paimon table. If there are multiple primary keys, connect them with comma, for example "buyer_id,seller_id".</td>
    </tr>
    <tr>
        <td><h5>--type_mapping</h5></td>
        <td>It is used to specify how to map MySQL data type to Paimon type.<br />
            Supported options:
            <ul>
                <li>"tinyint1-not-bool": maps MySQL TINYINT(1) to TINYINT instead of BOOLEAN.</li>
                <li>"to-nullable": ignores all NOT NULL constraints (except for primary keys).
                    This is used to solve the problem that Flink cannot accept the MySQL 'ALTER TABLE ADD COLUMN column type NOT NULL DEFAULT x' operation.
                </li>
                <li>"to-string": maps all MySQL types to STRING.</li>
                <li>"char-to-string": maps MySQL CHAR(length)/VARCHAR(length) types to STRING.</li>
                <li>"longtext-to-bytes": maps MySQL LONGTEXT types to BYTES.</li>
                <li>"bigint-unsigned-to-bigint": maps MySQL BIGINT UNSIGNED, BIGINT UNSIGNED ZEROFILL, SERIAL to BIGINT. You should ensure overflow won't occur when using this option.</li>
                <li>"decimal-no-change": Ignore decimal type change.</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td><h5>--sync_primary_keys_from_source_schema</h5></td>
        <td>This is used to specify if primary keys from source should be used in paimon schema if primary keys using --primary_keys are not specified. The default is true.</td>
    </tr>
    <tr>
        <td><h5>--computed_column</h5></td>
        <td>The definitions of computed columns. The argument field is from Kafka topic's table field name. See <a href="../overview/#computed-functions">here</a> for a complete list of configurations. </td>
    </tr>
    <tr>
        <td><h5>--kafka_conf</h5></td>
        <td>The configuration for Flink Kafka sources. Each configuration should be specified in the format `key=value`. `properties.bootstrap.servers`, `topic/topic-pattern`, `properties.group.id`,  and `value.format` are required configurations, others are optional.See its <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/kafka/#connector-options">document</a> for a complete list of configurations.</td>
    </tr>
    <tr>
        <td><h5>--catalog_conf</h5></td>
        <td>The configuration for Paimon catalog. Each configuration should be specified in the format "key=value". See <a href="//paimon.apache.org/docs/master/maintenance/configurations/#catalogoptions">here</a> for a complete list of catalog configurations.</td>
    </tr>
    <tr>
        <td><h5>--table_conf</h5></td>
        <td>The configuration for Paimon table sink. Each configuration should be specified in the format "key=value". See <a href="//paimon.apache.org/docs/master/maintenance/configurations/">here</a> for a complete list of table configurations.</td>
    </tr>
    </tbody>
</table>
<p>If the Paimon table you specify does not exist, this action will automatically create the table. Its schema will be derived from all specified Kafka topic&rsquo;s tables,it gets the earliest non-DDL data parsing schema from topic. If the Paimon table already exists, its schema will be compared against the schema of all specified Kafka topic&rsquo;s tables.</p>
<p>Example 1:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_table <span class="se">\
</span><span class="se"></span>    --warehouse hdfs:///path/to/warehouse <span class="se">\
</span><span class="se"></span>    --database test_db <span class="se">\
</span><span class="se"></span>    --table test_table <span class="se">\
</span><span class="se"></span>    --partition_keys pt <span class="se">\
</span><span class="se"></span>    --primary_keys pt,uid <span class="se">\
</span><span class="se"></span>    --computed_column <span class="s1">&#39;_year=year(age)&#39;</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.bootstrap.servers<span class="o">=</span>127.0.0.1:9020 <span class="se">\
</span><span class="se"></span>    --kafka_conf <span class="nv">topic</span><span class="o">=</span>order <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.group.id<span class="o">=</span><span class="m">123456</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf value.format<span class="o">=</span>canal-json <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">metastore</span><span class="o">=</span>hive <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">uri</span><span class="o">=</span>thrift://hive-metastore:9083 <span class="se">\
</span><span class="se"></span>    --table_conf <span class="nv">bucket</span><span class="o">=</span><span class="m">4</span> <span class="se">\
</span><span class="se"></span>    --table_conf changelog-producer<span class="o">=</span>input <span class="se">\
</span><span class="se"></span>    --table_conf sink.parallelism<span class="o">=</span><span class="m">4</span>
</code></pre></div><p>If the kafka topic doesn&rsquo;t contain message when you start the synchronization job, you must manually create the table
before submitting the job. You can define the partition keys and primary keys only, and the left columns will be added
by the synchronization job.</p>
<p>NOTE: In this case you shouldn&rsquo;t use &ndash;partition_keys or &ndash;primary_keys, because those keys are defined when creating
the table and can not be modified. Additionally, if you specified computed columns, you should also define all the argument
columns used for computed columns.</p>
<p>Example 2:
If you want to synchronize a table which has primary key &lsquo;id INT&rsquo;, and you want to compute a partition key &lsquo;part=date_format(create_time,yyyy-MM-dd)&rsquo;,
you can create a such table first (the other columns can be omitted):</p>
<div class="highlight"><pre class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">test_db</span><span class="p">.</span><span class="n">test_table</span> <span class="p">(</span>
    <span class="n">id</span> <span class="nb">INT</span><span class="p">,</span>                 <span class="c1">-- primary key
</span><span class="c1"></span>    <span class="n">create_time</span> <span class="k">TIMESTAMP</span><span class="p">,</span>  <span class="c1">-- the argument of computed column part
</span><span class="c1"></span>    <span class="n">part</span> <span class="n">STRING</span><span class="p">,</span>            <span class="c1">-- partition key
</span><span class="c1"></span>    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="n">part</span><span class="p">)</span> <span class="k">NOT</span> <span class="n">ENFORCED</span>
<span class="p">)</span> <span class="n">PARTITIONED</span> <span class="k">BY</span> <span class="p">(</span><span class="n">part</span><span class="p">);</span>
</code></pre></div><p>Then you can submit synchronization job:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_table <span class="se">\
</span><span class="se"></span>    --warehouse hdfs:///path/to/warehouse <span class="se">\
</span><span class="se"></span>    --database test_db <span class="se">\
</span><span class="se"></span>    --table test_table <span class="se">\
</span><span class="se"></span>    --computed_column <span class="s1">&#39;part=date_format(create_time,yyyy-MM-dd)&#39;</span> <span class="se">\
</span><span class="se"></span>    ... <span class="o">(</span>other conf<span class="o">)</span>
</code></pre></div><p>Example 3:
For some append data (such as log data), it can be treated as special CDC data with only INSERT operation type, so you can use &lsquo;format=json&rsquo; to synchronize such data to the Paimon table.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_table <span class="se">\
</span><span class="se"></span>    --warehouse hdfs:///path/to/warehouse <span class="se">\
</span><span class="se"></span>    --database test_db <span class="se">\
</span><span class="se"></span>    --table test_table <span class="se">\
</span><span class="se"></span>    --partition_keys pt <span class="se">\
</span><span class="se"></span>    --computed_column <span class="s1">&#39;pt=date_format(event_tm, yyyyMMdd)&#39;</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.bootstrap.servers<span class="o">=</span>127.0.0.1:9020 <span class="se">\
</span><span class="se"></span>    --kafka_conf <span class="nv">topic</span><span class="o">=</span>test_log <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.group.id<span class="o">=</span><span class="m">123456</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf value.format<span class="o">=</span>json <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">metastore</span><span class="o">=</span>hive <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">uri</span><span class="o">=</span>thrift://hive-metastore:9083 <span class="se">\
</span><span class="se"></span>    --table_conf sink.parallelism<span class="o">=</span><span class="m">4</span>
</code></pre></div><h2 id="synchronizing-databases">
  Synchronizing Databases
  <a class="anchor" href="#synchronizing-databases">#</a>
</h2>
<p>By using <a href="/docs/master/api/java/org/apache/paimon/flink/action/cdc/kafka/KafkaSyncDatabaseAction">KafkaSyncDatabaseAction</a> in a Flink DataStream job or directly through <code>flink run</code>, users can synchronize the multi topic or one topic into one Paimon database.</p>
<p>To use this feature through <code>flink run</code>, run the following shell command.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_database <span class="se">\
</span><span class="se"></span>    --warehouse &lt;warehouse-path&gt; <span class="se">\
</span><span class="se"></span>    --database &lt;database-name&gt; <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_mapping &lt;table-name&gt;<span class="o">=</span>&lt;paimon-table-name1&gt; <span class="o">[</span>--table_mapping &lt;table-name2&gt;<span class="o">=</span>&lt;paimon-table-name2&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_prefix &lt;paimon-table-prefix&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_suffix &lt;paimon-table-suffix&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_prefix_db &lt;db-name1&gt;<span class="o">=</span>&lt;table-prefix1&gt; <span class="o">[</span>--table_prefix_db &lt;db-name2&gt;<span class="o">=</span>&lt;table-prefix2&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_suffix_db &lt;db-name1&gt;<span class="o">=</span>&lt;table-suffix1&gt; <span class="o">[</span>--table_suffix_db &lt;db-name2&gt;<span class="o">=</span>&lt;table-suffix2&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--including_tables &lt;table-name<span class="p">|</span>name-regular-expr&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--excluding_tables &lt;table-name<span class="p">|</span>name-regular-expr&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--including_dbs &lt;database-name<span class="p">|</span>name-regular-expr&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--excluding_dbs &lt;database-name<span class="p">|</span>name-regular-expr&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--type_mapping to-string<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--partition_keys &lt;partition_keys&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--primary_keys &lt;primary-keys&gt;<span class="o">]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--computed_column &lt;<span class="s1">&#39;column-name=expr-name(args[, ...])&#39;</span>&gt; <span class="o">[</span>--computed_column ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--kafka_conf &lt;kafka-source-conf&gt; <span class="o">[</span>--kafka_conf &lt;kafka-source-conf&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--catalog_conf &lt;paimon-catalog-conf&gt; <span class="o">[</span>--catalog_conf &lt;paimon-catalog-conf&gt; ...<span class="o">]]</span> <span class="se">\
</span><span class="se"></span>    <span class="o">[</span>--table_conf &lt;paimon-table-sink-conf&gt; <span class="o">[</span>--table_conf &lt;paimon-table-sink-conf&gt; ...<span class="o">]]</span>
</code></pre></div>

<table class="configuration table table-bordered">
    <thead>
    <tr>
        <th class="text-left" style="width: 15%">Configuration</th>
        <th class="text-left" style="width: 85%">Description</th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <td><h5>--warehouse</h5></td>
        <td>The path to Paimon warehouse.</td>
    </tr>
    <tr>
        <td><h5>--database</h5></td>
        <td>The database name in Paimon catalog.</td>
    </tr>
    <tr>
        <td><h5>--ignore_incompatible</h5></td>
        <td>It is default false, in this case, if MySQL table name exists in Paimon and their schema is incompatible,an exception will be thrown. You can specify it to true explicitly to ignore the incompatible tables and exception.</td>
    </tr>
    <tr>
        <td><h5>--table_mapping</h5></td>
        <td>The table name mapping between source database and Paimon. For example, if you want to synchronize a source table named "test" to a Paimon table named "paimon_test", you can specify "--table_mapping test=paimon_test". Multiple mappings could be specified with multiple "--table_mapping" options. "--table_mapping" has higher priority than "--table_prefix" and "--table_suffix".</td>
    </tr>
    <tr>
        <td><h5>--table_prefix</h5></td>
        <td>The prefix of all Paimon tables to be synchronized except those specified by "--table_mapping" or "--table_prefix_db". For example, if you want all synchronized tables to have "ods_" as prefix, you can specify "--table_prefix ods_".</td>
    </tr>
    <tr>
        <td><h5>--table_suffix</h5></td>
        <td>The suffix of all Paimon tables to be synchronized except those specified by "--table_mapping" or "--table_suffix_db". The usage is same as "--table_prefix".</td>
    </tr>
    <tr>
        <td><h5>--table_prefix_db</h5></td>
        <td>The prefix of the Paimon tables to be synchronized from the specified db. For example, if you want to prefix the tables from db1 with "ods_db1_", you can specify "--table_prefix_db db1=ods_db1_". Multiple mappings could be specified multiple "--table_prefix_db" options. "--table_prefix_db" has higher priority than "--table_prefix".</td>
    </tr>
    <tr>
        <td><h5>--table_suffix_db</h5></td>
        <td>The suffix of the Paimon tables to be synchronized from the specified db. The usage is same as "--table_prefix_db".</td>
    </tr>
    <tr>
        <td><h5>--including_tables</h5></td>
        <td>It is used to specify which source tables are to be synchronized. You must use '|' to separate multiple tables.Because '|' is a special character, a comma is required, for example: 'a|b|c'.Regular expression is supported, for example, specifying "--including_tables test|paimon.*" means to synchronize table 'test' and all tables start with 'paimon'.</td>
    </tr>
    <tr>
        <td><h5>--excluding_tables</h5></td>
        <td>It is used to specify which source tables are not to be synchronized. The usage is same as "--including_tables". "--excluding_tables" has higher priority than "--including_tables" if you specified both.</td>
    </tr>
    <tr>
        <td><h5>--including_dbs</h5></td>
        <td>It is used to specify the databases within which the tables are to be synchronized. The usage is same as "--including_tables".</td>
    </tr>
    <tr>
        <td><h5>--excluding_dbs</h5></td>
        <td>It is used to specify the databases within which the tables are not to be synchronized. The usage is same as "--excluding_tables". "--excluding_dbs" has higher priority than "--including_dbs" if you specified both.</td>
    </tr>
    <tr>
        <td><h5>--type_mapping</h5></td>
        <td>It is used to specify how to map MySQL data type to Paimon type.<br />
            Supported options:
            <ul>
                <li>"tinyint1-not-bool": maps MySQL TINYINT(1) to TINYINT instead of BOOLEAN.</li>
                <li>"to-nullable": ignores all NOT NULL constraints (except for primary keys).
                    This is used to solve the problem that Flink cannot accept the MySQL 'ALTER TABLE ADD COLUMN column type NOT NULL DEFAULT x' operation.
                </li>
                <li>"to-string": maps all MySQL types to STRING.</li>
                <li>"char-to-string": maps MySQL CHAR(length)/VARCHAR(length) types to STRING.</li>
                <li>"longtext-to-bytes": maps MySQL LONGTEXT types to BYTES.</li>
                <li>"bigint-unsigned-to-bigint": maps MySQL BIGINT UNSIGNED, BIGINT UNSIGNED ZEROFILL, SERIAL to BIGINT. You should ensure overflow won't occur when using this option.</li>
                <li>"decimal-no-change": Ignore decimal type change.</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td><h5>--computed_column</h5></td>
        <td>The definitions of computed columns. The argument field is from Kafka topic's table field name. See <a href="../overview/#computed-functions">here</a> for a complete list of configurations. NOTICE: It returns null if the referenced column does not exist in the source table.</td>
    </tr>
    <tr>
        <td><h5>--eager_init</h5></td>
        <td>It is default false. If true, all relevant tables commiter will be initialized eagerly, which means those tables could be forced to create snapshot.</td>
    </tr>
    <tr>
    <tr>
        <td><h5>--partition_keys</h5></td>
        <td>The partition keys for Paimon table. If there are multiple partition keys, connect them with comma, for example "dt,hh,mm".
            If the keys are not in source table, the sink table won't set partition keys.</td>
    </tr>
    <tr>
        <td><h5>--multiple_table_partition_keys</h5></td>
        <td>The partition keys for each different Paimon table. If there are multiple partition keys, connect them with comma, for example
            <li>--multiple_table_partition_keys  tableName1=col1,col2.col3</li>
            <li>--multiple_table_partition_keys  tableName2=col4,col5.col6</li>
            <li>--multiple_table_partition_keys  tableName3=col7,col8.col9</li>
            If the keys are not in source table, the sink table won't set partition keys.</td>
    </tr>
    <tr>
        <td><h5>--primary_keys</h5></td>
        <td>The primary keys for Paimon table. If there are multiple primary keys, connect them with comma, for example "buyer_id,seller_id".
            If the keys are not provided, but the source has primary keys, the sink table will use source's primary keys.
            Otherwise, the sink table won't set primary keys.
            If the keys are not provided, but the source has primary keys, and you don't want to use source's primary keys,
            use --sync_primary_keys_from_source_schema.</td>
    </tr>
    <tr>
        <td><h5>--sync_primary_keys_from_source_schema</h5></td>
        <td>This is used to specify if primary keys from source should be used in paimon schema if primary keys using --primary_keys are not specified. The default is true.</td>
    </tr>
    <tr>
    <tr>
        <td><h5>--kafka_conf</h5></td>
        <td>The configuration for Flink Kafka sources. Each configuration should be specified in the format `key=value`. `properties.bootstrap.servers`, `topic/topic-pattern`, `properties.group.id`,  and `value.format` are required configurations, others are optional.See its <a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/kafka/#connector-options">document</a> for a complete list of configurations.</td>
    </tr>
    <tr>
        <td><h5>--catalog_conf</h5></td>
        <td>The configuration for Paimon catalog. Each configuration should be specified in the format "key=value". See <a href="//paimon.apache.org/docs/master/maintenance/configurations/#catalogoptions">here</a> for a complete list of catalog configurations.</td>
    </tr>
    <tr>
        <td><h5>--table_conf</h5></td>
        <td>The configuration for Paimon table sink. Each configuration should be specified in the format "key=value". See <a href="//paimon.apache.org/docs/master/maintenance/configurations/">here</a> for a complete list of table configurations.</td>
    </tr>
    </tbody>
</table>

<p>This action will build a single combined sink for all tables. For each Kafka topic&rsquo;s table to be synchronized, if the
corresponding Paimon table does not exist, this action will automatically create the table, and its schema will be derived
from all specified Kafka topic&rsquo;s tables. If the Paimon table already exists and its schema is different from that parsed
from Kafka record, this action will try to preform schema evolution.</p>
<p>Example</p>
<p>Synchronization from one Kafka topic to Paimon database.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_database <span class="se">\
</span><span class="se"></span>    --warehouse hdfs:///path/to/warehouse <span class="se">\
</span><span class="se"></span>    --database test_db <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.bootstrap.servers<span class="o">=</span>127.0.0.1:9020 <span class="se">\
</span><span class="se"></span>    --kafka_conf <span class="nv">topic</span><span class="o">=</span>order <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.group.id<span class="o">=</span><span class="m">123456</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf value.format<span class="o">=</span>canal-json <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">metastore</span><span class="o">=</span>hive <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">uri</span><span class="o">=</span>thrift://hive-metastore:9083 <span class="se">\
</span><span class="se"></span>    --table_conf <span class="nv">bucket</span><span class="o">=</span><span class="m">4</span> <span class="se">\
</span><span class="se"></span>    --table_conf changelog-producer<span class="o">=</span>input <span class="se">\
</span><span class="se"></span>    --table_conf sink.parallelism<span class="o">=</span><span class="m">4</span> <span class="se">\
</span><span class="se"></span>    --computed_column <span class="s1">&#39;pt=date_format(event_tm, yyyyMMdd)&#39;</span>
</code></pre></div><p>Synchronization from multiple Kafka topics to Paimon database.</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">&lt;FLINK_HOME&gt;/bin/flink run <span class="se">\
</span><span class="se"></span>    /path/to/paimon-flink-action-1.4-SNAPSHOT.jar <span class="se">\
</span><span class="se"></span>    kafka_sync_database <span class="se">\
</span><span class="se"></span>    --warehouse hdfs:///path/to/warehouse <span class="se">\
</span><span class="se"></span>    --database test_db <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.bootstrap.servers<span class="o">=</span>127.0.0.1:9020 <span class="se">\
</span><span class="se"></span>    --kafka_conf <span class="nv">topic</span><span class="o">=</span>order<span class="se">\;</span>logistic_order<span class="se">\;</span>user <span class="se">\
</span><span class="se"></span>    --kafka_conf properties.group.id<span class="o">=</span><span class="m">123456</span> <span class="se">\
</span><span class="se"></span>    --kafka_conf value.format<span class="o">=</span>canal-json <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">metastore</span><span class="o">=</span>hive <span class="se">\
</span><span class="se"></span>    --catalog_conf <span class="nv">uri</span><span class="o">=</span>thrift://hive-metastore:9083 <span class="se">\
</span><span class="se"></span>    --table_conf <span class="nv">bucket</span><span class="o">=</span><span class="m">4</span> <span class="se">\
</span><span class="se"></span>    --table_conf changelog-producer<span class="o">=</span>input <span class="se">\
</span><span class="se"></span>    --table_conf sink.parallelism<span class="o">=</span><span class="m">4</span>
</code></pre></div><h2 id="additional-kafka_config">
  Additional kafka_config
  <a class="anchor" href="#additional-kafka_config">#</a>
</h2>
<p>There are some useful options to build Flink Kafka Source, but they are not provided by flink-kafka-connector document. They are:</p>
<table class="table table-bordered">
    <thead>
      <tr>
        <th class="text-left">Key</th>
        <th class="text-left">Default</th>
        <th class="text-left">Type</th>
        <th class="text-left">Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>schema.registry.url</td>
          <td>(none)</td>
          <td>String</td>
          <td>When configuring "value.format=debezium-avro" which requires using the Confluence schema registry model for Apache Avro serialization, you need to provide the schema registry URL.</td>
        </tr>
    </tbody>
</table>
<h2 id="debezium-bson">
  Debezium-bson
  <a class="anchor" href="#debezium-bson">#</a>
</h2>
<p>The debezium-bson format is one of the formats supported by <a href="//paimon.apache.org/docs/master/cdc-ingestion/kafka-cdc/">Kafka CDC</a>.
It is the format obtained by collecting mongodb through debezium, which is similar to
<a href="https://nightlies.apache.org/flink/flink-docs-stable/docs/connectors/table/formats/debezium/">debezium-json</a> format.
However, MongoDB does not have a fixed schema, and the field types of each document may be different, so the before/after fields
in JSON are all string types, while the debezium-json format requires a JSON object type.</p>
<p>MongoDB BSON Jar can be downloaded from the <a href="https://mvnrepository.com/artifact/org.mongodb/bson">Maven repository</a></p>
<pre><code>bson-*.jar
</code></pre><blockquote class="book-hint info">
  The debezium bson format requires insert/update/delete event messages include the full document, and include a field that represents the state of the document before the change.
This requires setting debezium&rsquo;s capture.mode to change_streams_update_full_with_pre_image and <a href="https://debezium.io/documentation/reference/stable/connectors/mongodb.html#mongodb-property-capture-mode-full-update-type">capture.mode.full.update.type</a> to post_image.
Before version 6.0 of MongoDB, it was not possible to obtain &lsquo;Update Before&rsquo; information. Therefore, using the id field in the Kafka Key as &lsquo;Update before&rsquo; information
</blockquote>

<p>Here is a simple example for an update operation captured from a Mongodb customers collection in JSON format:</p>
<div class="highlight"><pre class="chroma"><code class="language-json" data-lang="json"><span class="p">{</span>
  <span class="nt">&#34;schema&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="s2">&#34;struct&#34;</span><span class="p">,</span>
    <span class="nt">&#34;fields&#34;</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span>
        <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="s2">&#34;string&#34;</span><span class="p">,</span>
        <span class="nt">&#34;optional&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;io.debezium.data.Json&#34;</span><span class="p">,</span>
        <span class="nt">&#34;version&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="nt">&#34;field&#34;</span><span class="p">:</span> <span class="s2">&#34;before&#34;</span>
      <span class="p">},</span>
      <span class="p">{</span>
        <span class="nt">&#34;type&#34;</span><span class="p">:</span> <span class="s2">&#34;string&#34;</span><span class="p">,</span>
        <span class="nt">&#34;optional&#34;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="nt">&#34;name&#34;</span><span class="p">:</span> <span class="s2">&#34;io.debezium.data.Json&#34;</span><span class="p">,</span>
        <span class="nt">&#34;version&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
        <span class="nt">&#34;field&#34;</span><span class="p">:</span> <span class="s2">&#34;after&#34;</span>
      <span class="p">},</span>
      <span class="err">...</span>
    <span class="p">]</span>
  <span class="p">},</span>
  <span class="nt">&#34;payload&#34;</span><span class="p">:</span> <span class="p">{</span>
    <span class="nt">&#34;before&#34;</span><span class="p">:</span> <span class="s2">&#34;{\&#34;_id\&#34;: {\&#34;$oid\&#34; : \&#34;596e275826f08b2730779e1f\&#34;}, \&#34;name\&#34; : \&#34;Anne\&#34;, \&#34;create_time\&#34; : {\&#34;$numberLong\&#34; : \&#34;1558965506000\&#34;}, \&#34;tags\&#34;:[\&#34;success\&#34;]}&#34;</span><span class="p">,</span>
    <span class="nt">&#34;after&#34;</span><span class="p">:</span> <span class="s2">&#34;{\&#34;_id\&#34;: {\&#34;$oid\&#34; : \&#34;596e275826f08b2730779e1f\&#34;}, \&#34;name\&#34; : \&#34;Anne\&#34;, \&#34;create_time\&#34; : {\&#34;$numberLong\&#34; : \&#34;1558965506000\&#34;}, \&#34;tags\&#34;:[\&#34;passion\&#34;,\&#34;success\&#34;]}&#34;</span><span class="p">,</span>
    <span class="nt">&#34;source&#34;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&#34;db&#34;</span><span class="p">:</span> <span class="s2">&#34;inventory&#34;</span><span class="p">,</span>
      <span class="nt">&#34;rs&#34;</span><span class="p">:</span> <span class="s2">&#34;rs0&#34;</span><span class="p">,</span>
      <span class="nt">&#34;collection&#34;</span><span class="p">:</span> <span class="s2">&#34;customers&#34;</span><span class="p">,</span>
      <span class="err">...</span>
    <span class="p">},</span>
    <span class="nt">&#34;op&#34;</span><span class="p">:</span> <span class="s2">&#34;u&#34;</span><span class="p">,</span>
    <span class="nt">&#34;ts_ms&#34;</span><span class="p">:</span> <span class="mi">1558965515240</span><span class="p">,</span>
    <span class="nt">&#34;ts_us&#34;</span><span class="p">:</span> <span class="mi">1558965515240142</span><span class="p">,</span>
    <span class="nt">&#34;ts_ns&#34;</span><span class="p">:</span> <span class="mi">1558965515240142879</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>This document from the MongoDB collection customers has 4 columns, the _id is a BSON ObjectID, name is a string,
create_time is a long, tags is an array of string. The following is the processing result in debezium-bson format:</p>
<p>Document Schema:</p>
<table>
<thead>
<tr>
<th>Field Name</th>
<th>Field Type</th>
<th>Key</th>
</tr>
</thead>
<tbody>
<tr>
<td>_id</td>
<td>STRING</td>
<td>Primary Key</td>
</tr>
<tr>
<td>name</td>
<td>STRING</td>
<td></td>
</tr>
<tr>
<td>create_time</td>
<td>STRING</td>
<td></td>
</tr>
<tr>
<td>tags</td>
<td>STRING</td>
<td></td>
</tr>
</tbody>
</table>
<p>Records:</p>
<table>
<thead>
<tr>
<th>RowKind</th>
<th>_id</th>
<th>name</th>
<th>create_time</th>
<th>tags</th>
</tr>
</thead>
<tbody>
<tr>
<td>-U</td>
<td>596e275826f08b2730779e1f</td>
<td>Anne</td>
<td>1558965506000</td>
<td>[&ldquo;success&rdquo;]</td>
</tr>
<tr>
<td>+U</td>
<td>596e275826f08b2730779e1f</td>
<td>Anne</td>
<td>1558965506000</td>
<td>[&ldquo;passion&rdquo;,&ldquo;success&rdquo;]</td>
</tr>
</tbody>
</table>
<p>Because the schema field of the event message does not have the field information of the document, the debezium-bson format does not require event messages to have schema information. The specific operations are as follows:</p>
<ul>
<li>Parse the before/after fields of the event message into BSONDocument.</li>
<li>Recursive traversal all fields of BSONDocument and convert BsonValue to Java Object.</li>
<li>All top-level fields of before/after are converted to string type, and _id is fixed to primary key</li>
<li>If the top-level fields of before/after is a basic type(such as Integer/Long, etc.), it is directly converted to a string, if not, it is converted to a JSON string</li>
</ul>
<p>Below is a list of top-level field BsonValue conversion examples:</p>
<table class="configuration table table-bordered">
    <thead>
    <tr>
        <th class="text-left" style="width: 20%">BsonValue Type</th>
        <th class="text-left" style="width: 40%">Json Value</th>
        <th class="text-left" style="width: 40%">Conversion Result String</th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <td><h5>BsonString</h5></td>
        <td>"hello"</td>
        <td>"hello"</td>
    </tr>
    <tr>
        <td><h5>BsonInt32</h5></td>
        <td>123</td>
        <td>"123"</td>
    </tr>
    <tr>
        <td><h5>BsonInt64</h5></td>
        <td>
            <ul>
                <li>1735934393769</li>
                <li>{"$numberLong": "1735934393769"}</li>
            </ul>
        </td>
        <td>"1735934393769"</td>
    </tr>
    <tr>
        <td><h5>BsonDouble</h5></td>
        <td>
            <ul>
                <li>{"$numberDouble": "3.14"}</li>
                <li>{"$numberDouble": "NaN"}</li>
                <li>{"$numberDouble": "Infinity"}</li>
                <li>{"$numberDouble": "-Infinity"}</li>
            </ul>
        </td>
        <td>
            <ul>
                <li>"3.14"</li>
                <li>"NaN"</li>
                <li>"Infinity"</li>
                <li>"-Infinity"</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td><h5>BsonBoolean</h5></td>
        <td>
            <ul>
                <li>true</li>
                <li>false</li>
            </ul>
        </td>
        <td>
            <ul>
                <li>"true"</li>
                <li>"false"</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td><h5>BsonArray</h5></td>
        <td>[1,2,{"$numberLong": "1735934393769"}]</td>
        <td>"[1,2,1735934393769]"</td>
    </tr>
    <tr>
        <td><h5>BsonObjectId</h5></td>
        <td>{"$oid": "596e275826f08b2730779e1f"}</td>
        <td>"596e275826f08b2730779e1f"</td>
    </tr>
    <tr>
        <td><h5>BsonDateTime</h5></td>
        <td>{"$date": 1735934393769 }</td>
        <td>"1735934393769"</td>
    </tr>
    <tr>
        <td><h5>BsonNull</h5></td>
        <td>null</td>
        <td>null</td>
    </tr>
    <tr>
        <td><h5>BsonUndefined</h5></td>
        <td>{"$undefined": true}</td>
        <td>null</td>
    </tr>
    <tr>
        <td><h5>BsonBinary</h5></td>
        <td>{"$binary": "uE2/4v5MSVOiJZkOo3APKQ==", "$type": "0"}</td>
        <td>"uE2/4v5MSVOiJZkOo3APKQ=="</td>
    </tr>
    <tr>
        <td><h5>BsonBinary(type=UUID)</h5></td>
        <td>{"$binary": "uE2/4v5MSVOiJZkOo3APKQ==", "$type": "4"}</td>
        <td>"b84dbfe2-fe4c-4953-a225-990ea3700f29"</td>
    </tr>
    <tr>
        <td><h5>BsonDecimal128</h5></td>
        <td>
            <ul>
                <li>{"$numberDecimal": "3.14"}</li>
                <li>{"$numberDecimal": "NaN"}</li>
            </ul>
        </td>
        <td>
            <ul>
                <li>"3.14"</li>
                <li>"NaN"</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td><h5>BsonRegularExpression</h5></td>
        <td>{"$regularExpression": {"pattern": "^pass$", "options": "i"}}</td>
        <td>"/^pass$/i"</td>
    </tr>
    <tr>
        <td><h5>BsonSymbol</h5></td>
        <td>{"$symbol": "symbol"}</td>
        <td>"symbol"</td>
    </tr>
    <tr>
        <td><h5>BsonTimestamp</h5></td>
        <td>{"$timestamp": {"t": 1736997330, "i": 2}}</td>
        <td>"1736997330"</td>
    </tr>
    <tr>
        <td><h5>BsonMinKey</h5></td>
        <td>{"$minKey": 1}</td>
        <td>"BsonMinKey"</td>
    </tr>
    <tr>
        <td><h5>BsonMaxKey</h5></td>
        <td>{"$maxKey": 1}</td>
        <td>"BsonMaxKey"</td>
    </tr>
    <tr>
        <td><h5>BsonJavaScript</h5></td>
        <td>{"$code": "function(){}"}</td>
        <td>"function(){}"</td>
    </tr>
    <tr>
        <td><h5>BsonJavaScriptWithScope</h5></td>
        <td>{"$code": "function(){}", "$scope": {"name": "Anne"}}</td>
        <td>'{"$code": "function(){}", "$scope": {"name": "Anne"}}'</td>
    </tr>
    <tr>
        <td><h5>BsonDocument</h5></td>
        <td>
<pre>
{
  "decimalPi": {"$numberDecimal": "3.14"},
  "doublePi": {"$numberDouble": "3.14"},
  "doubleNaN": {"$numberDouble": "NaN"},
  "decimalNaN": {"$numberDecimal": "NaN"},
  "long": {"$numberLong": "100"},
  "bool": true,
  "array": [
    {"$numberInt": "1"},
    {"$numberLong": "2"}
  ]
}
</pre>
        </td>
        <td>
<pre>
'{
  "decimalPi":3.14,
  "doublePi":3.14,
  "doubleNaN":"NaN",
  "decimalNaN":"NaN",
  "long":100,
  "bool":true,
  "array":[1,2]
}'
</pre>
        </td>
    </tr>
    </tbody>
</table>
</article>
 
      

      <footer class="book-footer">
        
  




<a href="//github.com/apache/paimon/edit/master/docs/content/cdc-ingestion/kafka-cdc.md" style="color:black"><i class="fa fa-edit fa-fw"></i>Edit This Page</a>


 
        


<hr style="margin-top: 20px; border: 1px solid #e5e5e5;" />

<table style="border-spacing: 10px;">
    <tbody>
    <tr>
        <td colspan="2">
            Copyright &copy; 2025 The Apache Software Foundation. Apache Paimon, Paimon, and its feather logo are
            trademarks of The Apache Software Foundation.
        </td>
    </tr>
    </tbody>
</table>

      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      
  

<nav id="TableOfContents"><h3>On This Page <button class="toc" onclick="collapseToc()"><i class="fa fa-compress" aria-hidden="true"></i></button></h3>
  <ul>
    <li><a href="#prepare-kafka-bundled-jar">Prepare Kafka Bundled Jar</a></li>
    <li><a href="#supported-formats">Supported Formats</a></li>
    <li><a href="#synchronizing-tables">Synchronizing Tables</a></li>
    <li><a href="#synchronizing-databases">Synchronizing Databases</a></li>
    <li><a href="#additional-kafka_config">Additional kafka_config</a></li>
    <li><a href="#debezium-bson">Debezium-bson</a></li>
  </ul>
</nav>

 
    </aside>
    <aside class="expand-toc">
      <button class="toc" onclick="expandToc()">
        <i class="fa fa-expand" aria-hidden="true"></i>
      </button>
    </aside>
    
  </main>

  
</body>

</html>












