{"title":"Release 0.6","type":"release","content":"<p>December 13, 2023 - Paimon Community (<a href=\"mailto:dev@paimon.apache.org\" target=\"_blank\" title=\"undefined\" rel=\"noopener\">dev@paimon.apache.org</a>)</p>\n<p>Apache Paimon PPMC has officially released Apache Paimon 0.6.0-incubating version. A total of 58 people contributed to\nthis version and completed over 400 Commits. Thank you to all contributors for their support!</p>\n<p>Some outstanding developments are:</p>\n<ol>\n<li>Flink Paimon CDC almost supports all mainstream data ingestion currently available.</li>\n<li>Flink 1.18 and Paimon supports CALL procedure, this will make table management easier.</li>\n<li>Cross partition update is available for production!</li>\n<li>Read-optimized table is introduced to enhance query performance.</li>\n<li>Append scalable mode is available for production!</li>\n<li>Paimon Presto module is available for production!</li>\n<li>Metrics system is integrated to Flink Metrics.</li>\n<li>Spark Paimon has made tremendous progress.</li>\n</ol>\n<p>For details, please refer to the following text.</p>\n<h2 id=\"flink\">Flink</h2><h3 id=\"paimon-cdc\">Paimon CDC</h3><p>Paimon CDC integrates Flink CDC, Kafka, Pulsar, etc., and provides comprehensive support in version 0.6:</p>\n<ol>\n<li>Kafka CDC supports formats: Canal Json, Debezium Json, Maxwell and OGG.</li>\n<li>Pulsar CDC is added, both Table Sync and Database Sync.</li>\n<li>Mongo CDC is available for production!</li>\n</ol>\n<h3 id=\"flink-batch-source\">Flink Batch Source</h3><p>By default, the parallelism of batch reads is the same as the number of splits, while the parallelism of stream reads\nis the same as the number of buckets, but not greater than scan.infer-parallelism.max (Default is 1024).</p>\n<h3 id=\"flink-streaming-source\">Flink Streaming Source</h3><p>Consumer-id is available for production!</p>\n<p>You can specify the consumer-id when streaming read table record consuming snapshot id in Paimon, the newly started \njob can continue to consume from the previous progress without resuming from the state. You can also set consumer.mode\nto at-least-once to get better checkpoint time. </p>\n<h3 id=\"flink-time-travel\">Flink Time Travel</h3><p>Flink 1.18 SQL supports Time Travel Query (You can also use dynamic option):</p>\n<pre class=\"code\"><code><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t <span class=\"token keyword\">FOR</span> SYSTEM_TIME <span class=\"token keyword\">AS</span> <span class=\"token keyword\">OF</span> <span class=\"token keyword\">TIMESTAMP</span> <span class=\"token string\">'2023-01-01 00:00:00'</span><span class=\"token punctuation\">;</span></code></pre><h3 id=\"flink-call-procedures\">Flink Call Procedures</h3><p>Flink 1.18 SQL supports Call Procedures:</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Procedure Name</th>\n<th align=\"center\">Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">compact</td>\n<td align=\"center\">CALL sys.compact(&#39;default.T&#39;, &#39;p=0&#39;, &#39;zorder&#39;, &#39;a,b&#39;, &#39;sink.parallelism=4&#39;)</td>\n</tr>\n<tr>\n<td align=\"center\">compact_database</td>\n<td align=\"center\">CALL sys.compact_database(&#39;db1</td>\n</tr>\n<tr>\n<td align=\"center\">create_tag</td>\n<td align=\"center\">CALL sys.create_tag(&#39;default.T&#39;, &#39;my_tag&#39;, 10)</td>\n</tr>\n<tr>\n<td align=\"center\">delete_tag</td>\n<td align=\"center\">CALL sys.delete_tag(&#39;default.T&#39;, &#39;my_tag&#39;)</td>\n</tr>\n<tr>\n<td align=\"center\">merge_into</td>\n<td align=\"center\">CALL sys.merge_into(&#39;default.T&#39;, &#39;&#39;, &#39;&#39;, &#39;default.S&#39;, &#39;T.id=S.order_id&#39;, &#39;&#39;, &#39;price=T.price+20&#39;, &#39;&#39;, &#39;*&#39;)</td>\n</tr>\n<tr>\n<td align=\"center\">remove_orphan_files</td>\n<td align=\"center\">CALL remove_orphan_files(&#39;default.T&#39;, &#39;2023-10-31 12:00:00&#39;)</td>\n</tr>\n<tr>\n<td align=\"center\">reset_consumer</td>\n<td align=\"center\">CALL sys.reset_consumer(&#39;default.T&#39;, &#39;myid&#39;, 10)</td>\n</tr>\n<tr>\n<td align=\"center\">rollback_to</td>\n<td align=\"center\">CALL sys.rollback_to(&#39;default.T&#39;, 10)</td>\n</tr>\n</tbody></table>\n<p>Flink 1.19 will support Named Arguments which will make it easier to use when there are multiple arguments.</p>\n<h3 id=\"committer-improvement\">Committer Improvement</h3><p>The Committee is responsible for submitting metadata, and sometimes it may have bottlenecks that can lead to \nbackpressure operations. In 0.6, we have the following optimizations:</p>\n<ol>\n<li>By default, paimon will delete expired snapshots synchronously. Users can use asynchronous expiration mode by \nsetting snapshot.expire.execution-mode to async to improve performance.</li>\n<li>You can use fine-grained-resource-management of Flink to increase committer heap memory and cpu only.</li>\n</ol>\n<h2 id=\"primary-key-table\">Primary Key Table</h2><h3 id=\"cross-partition-update\">Cross Partition Update</h3><p>Cross partition update is available for production!</p>\n<p>Currently Flink batch &amp; streaming writes are supported and has been applied by enterprises to production environments!\nHow to use Cross partition update:</p>\n<ol>\n<li>Primary keys not contain all partition fields.</li>\n<li>Use dynamic bucket mode, which means bucket is -1.</li>\n</ol>\n<p>This mode directly maintains the mapping of keys to partition and bucket, uses local disks, and initializes indexes by\nreading all existing keys in the table when starting write job. Although maintaining the index is necessary, this mode\nalso maintains high throughput performance. Please try it out.</p>\n<h3 id=\"read-optimized\">Read Optimized</h3><p>For Primary Key Table, it&#39;s a &#39;MergeOnRead&#39; technology. When reading data, multiple layers of LSM data are merged, and\nthe number of parallelism will be limited by the number of buckets. If you want to query fast enough in certain scenarios,\nbut can only find older data, you can query from read-optimized table: SELECT * FROM T$ro.</p>\n<p>But the freshness of the data cannot be guaranteed, you can configure &#39;full-compaction.delta-commits&#39; when writing data\nto ensure that data with a determined latency is read.</p>\n<p>StarRocks and other OLAP systems will release a version to greatly enhance query performance for read-optimized tables\nbased on Paimon 0.6.</p>\n<h3 id=\"partial-update\">Partial Update</h3><p>In 0.6, you can define aggregation functions for the partial-update merge engine with sequence group. This allows you\nto perform special aggregations on certain fields under certain conditions, such as count, sum, etc.</p>\n<h3 id=\"compaction\">Compaction</h3><p>We have introduced some asynchronous techniques to further improve the performance of Compaction! 20%+</p>\n<p>And 0.6 introduces the database compaction, you can run the following command to submit a compaction job for multiple\ndatabase. If you submit a streaming job, the job will continuously monitor new changes to the table and perform\ncompactions as needed.</p>\n<h2 id=\"append-table\">Append Table</h2><p>Append scalable mode is available for production!</p>\n<p>By defining &#39;bucket&#39; = &#39;-1&#39; to non-primary table, you can assign an append scalable mode for the table. This type of\ntable is an upgrade to Hive format. You can use it:</p>\n<ol>\n<li>Spark, Flink Batch Read &amp; Write, including INSERT OVERWRITE support.</li>\n<li>Flink, Spark Streaming Read &amp; Write, Flink will do small files compaction.</li>\n<li>You can sort (z-order) this table, which will greatly accelerate query performance, especially when there are filtering conditions related to sorting keys.</li>\n</ol>\n<p>You can set write-buffer-for-append option for append-only table, to apply situations where a large number of partitions\nare streaming written simultaneously.</p>\n<p>0.6 also introduce Hive Table Migration, Apache Hive supports ORC, Parquet file formats that could be migrated to Paimon.\nWhen migrating data to a paimon table, the origin table will be permanently disappeared. So please back up your data if\nyou still need the original table. The migrated table will be append table. You can use Flink Spark CALL procedure to\nmigrate Hive table.</p>\n<p>StarRocks and other OLAP systems will release a version to greatly enhance query performance for append tables based on Paimon 0.6.</p>\n<h2 id=\"tag-management\">Tag Management</h2><h3 id=\"upsert-to-partitioned\">Upsert To Partitioned</h3><p>The Tag will maintain the manifests and data files of the snapshot. Offline data warehouses require an immutable view\nevery day to ensure the idempotence of calculations. So we created a Tag mechanism to output these views.</p>\n<p>However, the traditional use of Hive data warehouses is more accustomed to using partitions to specify the query&#39;s Tag,\nand is more accustomed to using Hive computing engines.</p>\n<p>So, we introduce metastore.tag-to-partition and metastore.tag-to-partition.preview to mapping a non-partitioned primary\nkey table to the partition table in Hive metastore, and mapping the partition field to the name of the Tag to be fully\ncompatible with Hive.</p>\n<h3 id=\"tag-with-flink-savepoint\">Tag with Flink Savepoint</h3><p>You cannot recover a write job from an old Flink savepoint, which may cause issues with the Paimon table. In 0.6, we\navoided this situation where an exception is thrown when data anomalies occur, causing the job to fail to start.</p>\n<p>If you want to recover from the old savepoint, we recommend setting sink.savepoint.auto-tag to true to enable the\nfeature of automatically creating tags for Flink savepoint.</p>\n<h2 id=\"formats\">Formats</h2><p>0.6 upgrates ORC version to 1.8.3, and Parquet version to 1.13.1. ORC natively supports ZSTD in this version, which\nis a compression algorithm with a higher compression rate. We recommend using it when high compression rates are needed.</p>\n<h2 id=\"metrics-system\">Metrics System</h2><p>In 0.6, Paimon has built a metrics system to measure the behaviours of reading and writing, Paimon has supported\nbuilt-in metrics to measure operations of commits, scans, writes and compactions, which can be bridged to computing\nengine like Flink. The most important for streaming read is currentFetchEventTimeLag.</p>\n<h2 id=\"paimon-spark\">Paimon Spark</h2><ol>\n<li>Support Spark 3.5</li>\n<li>Structured Streaming: Supports serving as a Streaming Source, supports source side traffic control through custom read triggers, and supports stream read changelog</li>\n<li>Row Level Operation: DELETE optimization, supporting UPDATE and MERGE INTO</li>\n<li>Call Procedure: Add compact and migrate_table, migrate_file, remove_orphan_files, create_tag, delete_tag, rollback</li>\n<li>Query optimization: Push down filter optimization, support for Push down limit, and runtime filter (DPP)</li>\n<li>Other: Truncate Table optimization, support for CTAS, support for Truncate Partition</li>\n</ol>\n<h2 id=\"paimon-trino\">Paimon Trino</h2><p>The Paimon Trino module mainly performs the following tasks to accelerate queries:</p>\n<ol>\n<li>Optimize the issue of converting pages to avoid memory overflow caused by large pages</li>\n<li>Implemented Limit Pushdown and can combine partition pruning</li>\n</ol>\n<h2 id=\"paimon-presto\">Paimon Presto</h2><p>The Paimon Presto module is available for production! The following capabilities have been added:</p>\n<ol>\n<li>Implement Filter Pushdown, which allows Paimon Presto to be available for production</li>\n<li>Use the Inject mode, which allows Paimon Catalog to reside in the process and improve query speed</li>\n</ol>\n<h2 id=\"whats-next\">What's next?</h2><p>Report your requirements!</p>\n","toc":[{"depth":2,"text":"Flink","id":"flink"},{"depth":3,"text":"Paimon CDC","id":"paimon-cdc"},{"depth":3,"text":"Flink Batch Source","id":"flink-batch-source"},{"depth":3,"text":"Flink Streaming Source","id":"flink-streaming-source"},{"depth":3,"text":"Flink Time Travel","id":"flink-time-travel"},{"depth":3,"text":"Flink Call Procedures","id":"flink-call-procedures"},{"depth":3,"text":"Committer Improvement","id":"committer-improvement"},{"depth":2,"text":"Primary Key Table","id":"primary-key-table"},{"depth":3,"text":"Cross Partition Update","id":"cross-partition-update"},{"depth":3,"text":"Read Optimized","id":"read-optimized"},{"depth":3,"text":"Partial Update","id":"partial-update"},{"depth":3,"text":"Compaction","id":"compaction"},{"depth":2,"text":"Append Table","id":"append-table"},{"depth":2,"text":"Tag Management","id":"tag-management"},{"depth":3,"text":"Upsert To Partitioned","id":"upsert-to-partitioned"},{"depth":3,"text":"Tag with Flink Savepoint","id":"tag-with-flink-savepoint"},{"depth":2,"text":"Formats","id":"formats"},{"depth":2,"text":"Metrics System","id":"metrics-system"},{"depth":2,"text":"Paimon Spark","id":"paimon-spark"},{"depth":2,"text":"Paimon Trino","id":"paimon-trino"},{"depth":2,"text":"Paimon Presto","id":"paimon-presto"},{"depth":2,"text":"What's next?","id":"whats-next"}],"alias":"release-0.6","version":"0.6.0","weight":60}